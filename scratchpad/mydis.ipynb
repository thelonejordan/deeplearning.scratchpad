{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc32c05-d61b-4ed3-9845-05741b68e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fbe86a-047c-40c3-a29b-1bc9192e6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd55061f-3216-45d8-8cd4-f07eb81c13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llama3.transformer import Transformer\n",
    "from models.llama3.tokenizer import Tokenizer\n",
    "from models.llama3.config import LlamaConfig\n",
    "from models.llama3.load import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bf6e42-52ca-4666-9ecf-3257e932cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"The theory of relativity states that the speed of light is constant in all reference frames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4264b4d-7d51-43dd-bf71-f4ac57f3914a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c6e1bcb8bf402a83b3ae08f78be8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6660c46c1ed46af912bc44135eaa927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded tiktoken model from /Users/jyotirmaya.mahanta/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/original/tokenizer.model\n",
      "#words: 128256 - BOS ID: 128000 - EOS ID: 128001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc9a41a87ed41dfb54ecb531491dc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3.21B\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\"\n",
    "model, tokenizer, config = build(\n",
    "    max_seq_len=19,\n",
    "    max_batch_size=1,\n",
    "    model_desc=\"3B\",\n",
    "    version=2,\n",
    "    safetensors=True,\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bab12a0-3a85-4156-9045-9e9acd6c62e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_id = tokenizer.eos_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c944e726-a905-43ac-957c-7f157bb8cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128000, 791, 10334, 315, 1375, 44515, 5415, 430, 279, 4732, 315, 3177, 374, 6926, 304, 682, 5905, 14418]]\n"
     ]
    }
   ],
   "source": [
    "inputs = [tokenizer.encode(s, bos=True, eos=False) for s in prompts]\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72a299a-9731-4a32-8016-00ba0ae5a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tokens = inputs\n",
    "max_batch_size, max_seq_len = config.max_batch_size, config.max_seq_len\n",
    "bsz = len(prompt_tokens)\n",
    "# assert bsz <= max_batch_size, (bsz, max_batch_size)\n",
    "max_gen_len = config.max_seq_len\n",
    "min_prompt_len = min(len(t) for t in prompt_tokens)\n",
    "max_prompt_len = max(len(t) for t in prompt_tokens)\n",
    "# assert max_prompt_len <= max_seq_len\n",
    "total_len = min(max_seq_len, max_gen_len + max_prompt_len)\n",
    "pad_id = tokenizer.pad_id\n",
    "tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=device)\n",
    "for k, t in enumerate(prompt_tokens):\n",
    "    tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long, device=device)\n",
    "# if logprobs:\n",
    "#     token_logprobs = torch.zeros_like(tokens, dtype=torch.float)\n",
    "prev_pos = 0\n",
    "eos_reached = torch.tensor([False] * bsz, device=device)\n",
    "input_text_mask = tokens != pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c9449e-4780-440e-a841-fa20de49c1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([315], device='mps:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_pos = 0\n",
    "cur_pos = min_prompt_len\n",
    "logits = model.forward(tokens[:, prev_pos:cur_pos], prev_pos)\n",
    "probs = torch.softmax(logits[:, -1], dim=-1)\n",
    "next_token = torch.argmax(logits[:, -1], dim=-1)\n",
    "next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caa8f5fe-85e3-4785-9f5a-53ae177f7cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,    791,  10334,    315,   1375,  44515,   5415,    430,    279,\n",
       "           4732,    315,   3177,    374,   6926,    304,    682,   5905,  14418]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = tokens[:, prev_pos:cur_pos]\n",
    "toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d97e02-6e30-4bd3-8243-f5ebe4695871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs, logprobs = generate(inputs, model, tokenizer, config, device, logprobs=False)\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73be6395-a20f-436c-86f7-3ad70b8bd65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18, 3072])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0011, -0.0007, -0.0046,  ..., -0.0015, -0.0021,  0.0018],\n",
       "         [ 0.0065, -0.0332, -0.0101,  ..., -0.0303,  0.0197, -0.0017],\n",
       "         [-0.0264, -0.0152, -0.0183,  ...,  0.0131,  0.0369, -0.0364],\n",
       "         ...,\n",
       "         [ 0.0013,  0.0025, -0.0155,  ...,  0.0320,  0.0058, -0.0131],\n",
       "         [ 0.0454, -0.0099,  0.0054,  ..., -0.0061, -0.0052, -0.0125],\n",
       "         [-0.0330, -0.0001,  0.0117,  ..., -0.0094,  0.0117, -0.0187]]],\n",
       "       device='mps:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = model.model.embed_tokens(toks)\n",
    "print(h.shape)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9051c9e6-3f92-4eaf-a6b9-6189589a3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = toks.size(1)\n",
    "start_pos = prev_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3609a295-6e40-49df-bed0-e7745dc23a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000+0.0000e+00j,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n",
       "          ...,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n",
       "          1.0000+0.0000e+00j],\n",
       "        [ 0.5403+8.4147e-01j,  0.6861+7.2746e-01j,  0.7878+6.1596e-01j,\n",
       "          ...,  1.0000+3.6997e-06j,  1.0000+3.0139e-06j,\n",
       "          1.0000+2.4551e-06j],\n",
       "        [-0.4161+9.0930e-01j, -0.0584+9.9829e-01j,  0.2412+9.7048e-01j,\n",
       "          ...,  1.0000+7.3994e-06j,  1.0000+6.0277e-06j,\n",
       "          1.0000+4.9103e-06j],\n",
       "        ...,\n",
       "        [-0.7597+6.5029e-01j,  0.9404-3.4018e-01j, -0.8632-5.0488e-01j,\n",
       "          ...,  1.0000+5.5496e-05j,  1.0000+4.5208e-05j,\n",
       "          1.0000+3.6827e-05j],\n",
       "        [-0.9577-2.8790e-01j,  0.8927+4.5066e-01j, -0.3690-9.2942e-01j,\n",
       "          ...,  1.0000+5.9196e-05j,  1.0000+4.8222e-05j,\n",
       "          1.0000+3.9282e-05j],\n",
       "        [-0.2752-9.6140e-01j,  0.2847+9.5862e-01j,  0.2818-9.5948e-01j,\n",
       "          ...,  1.0000+6.2895e-05j,  1.0000+5.1236e-05j,\n",
       "          1.0000+4.1737e-05j]], device='mps:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_cis = model.freqs_cis[start_pos : start_pos + seqlen]\n",
    "print(freqs_cis.shape)\n",
    "freqs_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bcba89-249f-4845-9af0-0eb709c855ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
